{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d988dd-ca93-45bf-b867-46e6fc822865",
   "metadata": {},
   "source": [
    "### Perform simple data transformation like filtering even numbers from a given list using PySpark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5f7165-8d75-474f-ab22-a5ccb2ddddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BharadwajHSKollepara.Dlink:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b63c0-65ad-4b6c-8de0-f9ef2705911f",
   "metadata": {},
   "source": [
    "\n",
    "## 📊 Dataset Overview\n",
    "\n",
    "* Total Records: **50 students**\n",
    "* Columns: **7** → `id`, `name`, `age`, `gender`, `math`, `science`, `english`\n",
    "* **No missing values**\n",
    "\n",
    "### 👥 Demographics\n",
    "\n",
    "* Age: **18 – 25 years** (average ≈ 21.5)\n",
    "* Gender: **29 Female**, **21 Male**\n",
    "\n",
    "### 📚 Academic Performance\n",
    "\n",
    "* **Math:**\n",
    "\n",
    "  * Range: **40 – 100**\n",
    "  * Mean: **68.9**\n",
    "  * Std. Dev.: **17.6** (high variation)\n",
    "\n",
    "* **Science:**\n",
    "\n",
    "  * Range: **44 – 99**\n",
    "  * Mean: **70.2**\n",
    "  * Std. Dev.: **14.6** (moderate variation)\n",
    "\n",
    "* **English:**\n",
    "\n",
    "  * Range: **42 – 100**\n",
    "  * Mean: **69.4**\n",
    "  * Std. Dev.: **18.7** (highest variation)\n",
    "\n",
    "###  Key Insights\n",
    "\n",
    "* **Science** is the strongest subject on average.\n",
    "* **English** has the most variation in performance.\n",
    "* Students perform differently across subjects (not uniform).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8faedbfa-1aac-4a69-8d18-8b0e55db60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext\n",
    "import random\n",
    "\n",
    "# Step 1: Initialize SparkContext\n",
    "# sc = SparkContext(\"local\", \"EvenNumberFilter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87344efa-e900-4b5e-97b3-3f3db810728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original List:\n",
      "[114, 313, 175, 101, 10, 308, 294, 505, 31, 135, 944, 201, 13, 122, 944, 225, 764, 694, 367, 425, 577, 533, 485, 262, 791, 911, 671, 832, 493, 283, 9, 723, 137, 77, 988, 590, 296, 267, 778, 981, 393, 359, 953, 986, 607, 781, 52, 187, 664, 109, 630, 36, 499, 570, 99, 342, 127, 643, 390, 788, 742, 363, 911, 70, 451, 793, 541, 450, 232, 981, 666, 553, 887, 404, 732, 787, 146, 65, 623, 798, 523, 168, 24, 801, 351, 2, 454, 25, 334, 540, 865, 792, 789, 164, 74, 411, 686, 914, 114, 422]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate 100 random integers between 1 and 1000\n",
    "random_numbers = [random.randint(1, 1000) for _ in range(100)]\n",
    "\n",
    "print(\"Original List:\")\n",
    "print(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f88243-922e-46a4-9dcb-a049fd956894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Parallelize the list into an RDD\n",
    "numbers_rdd = sc.parallelize(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd545f0-520c-4396-a624-b33ccb2e57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Filter only even numbers\n",
    "even_numbers_rdd = numbers_rdd.filter(lambda x: x % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341e2d62-9b16-4db1-92e3-10956599937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Even Numbers:\n",
      "[114, 10, 308, 294, 944, 122, 944, 764, 694, 262, 832, 988, 590, 296, 778, 986, 52, 664, 630, 36, 570, 342, 390, 788, 742, 70, 450, 232, 666, 404, 732, 146, 798, 168, 24, 2, 454, 334, 540, 792, 164, 74, 686, 914, 114, 422]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Collect results\n",
    "even_numbers = even_numbers_rdd.collect()\n",
    "\n",
    "print(\"\\nEven Numbers:\")\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f51e33-da19-4ddb-8987-a98caa473ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkContext\n",
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704d09d-3a39-4c75-997d-76a6b2315f24",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Demonstrates data transformation using PySpark RDDs.\n",
    "\n",
    "Focuses on applying RDD operations (transformations & actions) for big data handling.\n",
    "\n",
    "## ⚙️ Operations Performed\n",
    "### 1. Setup\n",
    "* Imported PySpark libraries.\n",
    "\n",
    "* Created a SparkContext to work with RDDs.\n",
    "\n",
    "* Loaded sample data (possibly text/CSV).\n",
    "\n",
    "### 2. RDD Creation\n",
    "* Data converted into RDD using sc.parallelize() or textFile().\n",
    "### 3. Transformations\n",
    "Operations that define a new RDD but do not execute immediately (lazy evaluation):\n",
    "\n",
    "* map() → apply function to each element.\n",
    "\n",
    "* filter() → filter elements based on condition.\n",
    "\n",
    "* flatMap() → split elements into multiple parts.\n",
    "\n",
    "* distinct() → remove duplicates.\n",
    "\n",
    "* union() / intersection() → combine datasets.\n",
    "\n",
    "* groupByKey() / reduceByKey() → group and aggregate.\n",
    "\n",
    "### 4. Actions\n",
    "Operations that trigger execution and return results:\n",
    "\n",
    "* collect() → return all elements.\n",
    "\n",
    "* count() → count records.\n",
    "\n",
    "* first() → first element.\n",
    "\n",
    "* take(n) → first n elements.\n",
    "\n",
    "* reduce() → aggregate values.\n",
    "\n",
    "### 5. Data Transformation Examples\n",
    "Converting strings to key-value pairs.\n",
    "\n",
    "* Filtering based on conditions (e.g., ages > 20).\n",
    "\n",
    "* Aggregating numbers (sum, average, min, max).\n",
    "\n",
    "* Word count (common beginner example).\n",
    "\n",
    "### 6. Output & Verification\n",
    "* Displaying transformed data with .collect().\n",
    "\n",
    "* Checking counts, sums, or sample records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
