{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bc2958-57cc-4da5-b507-fe2b46273d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"PatentDataAnalysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4982f44a-9fb7-47f9-a64d-252291e352cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------------+---------------------+------------------+--------------+--------------------+------------------+-----------+------------+\n",
      "|PUBLICATION_NUMBER|PUBLICATION_DATE|IPO_LOCATION|APPLICATION_TYPE_DESC|APPLICATION_NUMBER|DATE_OF_FILING|  TITLE_OF_INVENTION|FIELD_OF_INVENTION|NO_OF_PAGES|NO_OF_CLAIMS|\n",
      "+------------------+----------------+------------+---------------------+------------------+--------------+--------------------+------------------+-----------+------------+\n",
      "|           50/2016|      02/12/2016|     Kolkata| CONVENTION APPLIC...|      108/KOL/2009|    20/01/2009|MULTI-SPEED TRANS...|        MECHANICAL|         26|          21|\n",
      "|           50/2016|      02/12/2016|     Kolkata| PCT NATIONAL PHAS...|   1777/KOLNP/2010|    17/05/2010|PROCESS FOR PREPA...|         CHEMISTRY|         38|          12|\n",
      "|           52/2016|      16/12/2016|     Kolkata| PCT NATIONAL PHAS...|   2277/KOLNP/2010|    22/06/2010|TEXTILE SEMIFINIS...|           POLYMER|         13|          14|\n",
      "|           53/2016|      23/12/2016|     Kolkata| PCT NATIONAL PHAS...|   2537/KOLNP/2010|    13/07/2010|DESALINATION SYST...|         CHEMISTRY|         67|          15|\n",
      "|           53/2016|      23/12/2016|     Kolkata| PCT NATIONAL PHAS...|   3269/KOLNP/2010|    03/09/2010|METHOD FOR PREPAR...|         CHEMISTRY|         17|          15|\n",
      "+------------------+----------------+------------+---------------------+------------------+--------------+--------------------+------------------+-----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Weekly_Patent_Application_Granted.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f831d780-bc25-47ea-9c42-4df326162b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PUBLICATION_NUMBER: string (nullable = true)\n",
      " |-- PUBLICATION_DATE: string (nullable = true)\n",
      " |-- IPO_LOCATION: string (nullable = true)\n",
      " |-- APPLICATION_TYPE_DESC: string (nullable = true)\n",
      " |-- APPLICATION_NUMBER: string (nullable = true)\n",
      " |-- DATE_OF_FILING: string (nullable = true)\n",
      " |-- TITLE_OF_INVENTION: string (nullable = true)\n",
      " |-- FIELD_OF_INVENTION: string (nullable = true)\n",
      " |-- NO_OF_PAGES: string (nullable = true)\n",
      " |-- NO_OF_CLAIMS: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "851989c1-8ab2-44f5-92e1-fc926e6bbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.dropDuplicates()\n",
    "df = df.na.drop(subset=[\"PUBLICATION_DATE\", \"DATE_OF_FILING\", \"FIELD_OF_INVENTION\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90ebad63-9bf9-4a97-9ecb-b594a0f7a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df = df.withColumn(\"PUBLICATION_DATE\",\n",
    "                   expr(\"try_to_timestamp(PUBLICATION_DATE, 'dd/MM/yyyy')\"))\n",
    "df = df.withColumn(\"DATE_OF_FILING\",\n",
    "                   expr(\"try_to_timestamp(DATE_OF_FILING, 'dd/MM/yyyy')\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c622be9-67bd-458a-8433-0970d1bb0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.filter(col(\"PUBLICATION_DATE\").isNotNull() & col(\"DATE_OF_FILING\").isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72223be3-bcbd-42da-89bc-1367b367a87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "185c8780-6b0b-4122-94f9-e815b7838321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, datediff\n",
    "\n",
    "df = df.withColumn(\"YEAR\", year(col(\"PUBLICATION_DATE\")))\n",
    "df = df.withColumn(\"FILING_YEAR\", year(col(\"DATE_OF_FILING\")))\n",
    "df = df.withColumn(\"FILING_MONTH\", month(col(\"DATE_OF_FILING\")))\n",
    "df = df.withColumn(\"Time_to_Grant\", datediff(col(\"PUBLICATION_DATE\"), col(\"DATE_OF_FILING\")))\n",
    "\n",
    "# Filter out negative differences\n",
    "df = df.filter(col(\"Time_to_Grant\") >= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0165a7c4-7b2a-40bf-bff5-b13517ff369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(col(\"Time_to_Grant\") >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "341452f9-1b9f-4b14-a635-fd12f9274d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PUBLICATION_NUMBER: string (nullable = true)\n",
      " |-- PUBLICATION_DATE: timestamp (nullable = true)\n",
      " |-- IPO_LOCATION: string (nullable = true)\n",
      " |-- APPLICATION_TYPE_DESC: string (nullable = true)\n",
      " |-- APPLICATION_NUMBER: string (nullable = true)\n",
      " |-- DATE_OF_FILING: timestamp (nullable = true)\n",
      " |-- TITLE_OF_INVENTION: string (nullable = true)\n",
      " |-- FIELD_OF_INVENTION: string (nullable = true)\n",
      " |-- NO_OF_PAGES: string (nullable = true)\n",
      " |-- NO_OF_CLAIMS: string (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- FILING_YEAR: integer (nullable = true)\n",
      " |-- FILING_MONTH: integer (nullable = true)\n",
      " |-- Time_to_Grant: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d0967fa-da2b-4ed0-9171-e185e8fd76c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf = df.toPandas()\n",
    "\n",
    "pdf.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc3ed78d-03c0-4482-b29c-8bfb91e60b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output\n"
     ]
    }
   ],
   "source": [
    "print(\"Saved output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a56af9-2e96-4790-94df-52638c7f02c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (PySpark)",
   "language": "python",
   "name": "python310-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
